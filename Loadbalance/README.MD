## 何为LB
* 字面意思是将负载均摊到各个单元，此处单元不限于代码、硬件或集群。

## 算法

* 轮询
```
优点：实现简单，每个集群节点平均分担所有的请求。

缺点：当集群中服务器硬件配置不同、性能差别大时，无法区别对待。引出下面的算法。
```
* 权重
```
优点：可以根据机器的具体情况，分配不同的负载，达到能者多劳。

缺点：需要额外管理加权系数。
```
* 随机
```
随机选取集群中的某个节点来处理该请求，由概率论的知识可知，随着请求量的变大，随机算法会逐渐演变为轮询算法，即集群各个节点会处理差不多数量的请求。

优点：简单使用，不需要额外的配置和算法。

缺点：随机数的特点是在数据量大到一定量时才能保证均衡，所以如果请求量有限的话，可能会达不到均衡负载的要求。
```

### 硬件
* F5
* Netscaler
### OS操作系统
* LVS

### OSI七层模型
* [第二层_数据链路层](.)
* [第三层_网络层](.)
* [第四层_传输层](.)
* [第七层_应用层](.)
### Code代码
### 微服务
### 开源
* LVS
* DPVS

---
## 为何LB
* 最优化资源使用、最大吞吐率、最小化响应时间、同时避免过载的目的。

---
## 如何LB
* Netfilter框架
```
iptables 作为用户空间编写和传递规则的工具，netfilter 是内核态的 Linux 防火墙机制。

```
* LVS
```
LVS 是基于 netfilter 框架
在 lvs 中，节点分为 Director Server 和 Real Server 两个角色，其中 Director Server 是负载均衡器所在节点，而 Real Server 则是后端服务节点.
```
* DPDK
```
基于DPDK的高性能四层负载均衡器（Layer-4 load balancer），DPVS的名字来源于DPDK+LVS，注意这里的LVS是阿里巴巴改进版的LVS。
官方声称DPVS的包处理速度，1个工作线程可以达到 2.3Mpps，6个工作线程可以达到万兆网卡小包的转发线速（约 12Mpps)。这主要是因为DPVS绕过了内核复杂的协议栈，并采用轮询的方式收发数据包，避免了锁、内核中断、上下文切换、内核态和用户态数据拷贝产生的性能开销。
```
* 一个CPU核心+一个网卡+一个进程
```
网卡队列/CPU绑定
现在的服务器网卡绝大多数都是多队列网卡，支持多个队列同时收发数据，让不同的 CPU 处理不同的网卡队列的流量，分摊工作量，DPVS将其和CPU进行绑定，利用DPDK 的 API 实现一个网卡的一个收发队列对应一个CPU核心和一个Worker进程，实现一一对应和绑定，从而实现了处理能力随CPU核心、网卡队列数的增加而线性增长，并且很好地实现了并行处理和线性扩展。
关键数据无锁化
内核性能问题的一大原因就是资源共享和锁。所以，被频繁访问的关键数据需要尽可能的实现无锁化，其中一个方法是将数据做到 per-cpu 化，即每个CPU核心只处理自己本地的数据，不需要访问其他CPU的数据，这样就可以避免加锁。
```
